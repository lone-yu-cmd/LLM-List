{
  "$schema": "./schema/llm_registry_schema.json",
  "version": "1.0.0",
  "updated_at": "2026-01-27",
  "description": "Registry of LLM providers, their API configurations, and supported models.",
  "providers": [
    {
      "id": "anthropic",
      "name": "Anthropic",
      "description": "AI safety and research company, creator of Claude.",
      "website": "https://www.anthropic.com",
      "docs_url": "https://docs.anthropic.com/claude/reference/getting-started-with-the-api",
      "api_config": {
        "protocol": "rest",
        "protocol_format": "anthropic",
        "base_url": "https://api.anthropic.com/v1",
        "auth": {
          "type": "api_key",
          "header_key": "x-api-key",
          "env_var_suggestion": "ANTHROPIC_API_KEY"
        },
        "endpoints": {
          "messages": {
            "path": "/messages",
            "method": "POST",
            "supports_stream": true
          }
        },
        "error_codes": [
          {
            "code": "400",
            "description": "Invalid Request"
          },
          {
            "code": "401",
            "description": "Authentication Error"
          },
          {
            "code": "403",
            "description": "Permission Error"
          },
          {
            "code": "429",
            "description": "Rate Limit Error"
          },
          {
            "code": "500",
            "description": "Api Error"
          },
          {
            "code": "529",
            "description": "Overloaded Error"
          }
        ]
      },
      "pricing_currency": "USD",
      "models": [
        {
          "id": "claude-sonnet-4-5-20250929",
          "name": "Claude 4.5 Sonnet",
          "type": "chat",
          "description": "High-intelligence model with structured output support and context management.",
          "features": [
            "vision",
            "function_calling",
            "structured_outputs",
            "thinking"
          ],
          "context_window": 200000,
          "max_output_tokens": 8192
        },
        {
          "id": "claude-3-7-sonnet-20250219",
          "name": "Claude 3.7 Sonnet",
          "type": "chat",
          "description": "Balanced model for enterprise workloads.",
          "features": [
            "vision",
            "function_calling"
          ],
          "context_window": 200000,
          "max_output_tokens": 8192
        },
        {
          "id": "claude-3-5-sonnet-20240620",
          "name": "Claude 3.5 Sonnet",
          "type": "chat",
          "description": "Previous generation high-performance model.",
          "features": [
            "vision",
            "function_calling"
          ],
          "context_window": 200000,
          "max_output_tokens": 8192
        },
        {
          "id": "claude-3-opus-20240229",
          "name": "Claude 3 Opus",
          "type": "chat",
          "description": "Most powerful model for highly complex tasks.",
          "features": [
            "vision",
            "function_calling"
          ],
          "context_window": 200000,
          "max_output_tokens": 4096
        },
        {
          "id": "claude-3-haiku-20240307",
          "name": "Claude 3 Haiku",
          "type": "chat",
          "description": "Fastest and most compact model for near-instant responsiveness.",
          "features": [
            "vision",
            "function_calling"
          ],
          "context_window": 200000,
          "max_output_tokens": 4096
        }
      ]
    },
    {
      "id": "deepseek",
      "name": "DeepSeek",
      "description": "DeepSeek is an AI research company known for its open-source models and reasoning capabilities.",
      "website": "https://www.deepseek.com",
      "docs_url": "https://api-docs.deepseek.com",
      "api_config": {
        "protocol": "rest",
        "protocol_format": "openai",
        "base_url": "https://api.deepseek.com",
        "auth": {
          "type": "api_key",
          "header_key": "Authorization",
          "token_prefix": "Bearer",
          "env_var_suggestion": "DEEPSEEK_API_KEY"
        },
        "endpoints": {
          "chat": {
            "path": "/chat/completions",
            "method": "POST",
            "supports_stream": true
          },
          "models": {
            "path": "/models",
            "method": "GET"
          }
        },
        "error_codes": [
          {
            "code": "400",
            "description": "Validation Error"
          },
          {
            "code": "401",
            "description": "Authentication Failed"
          },
          {
            "code": "402",
            "description": "Insufficient Balance"
          },
          {
            "code": "422",
            "description": "Invalid Parameters"
          },
          {
            "code": "429",
            "description": "Rate Limit Exceeded"
          },
          {
            "code": "500",
            "description": "Server Error"
          },
          {
            "code": "503",
            "description": "Server Overloaded"
          }
        ]
      },
      "pricing_currency": "USD",
      "models": [
        {
          "id": "deepseek-chat",
          "name": "DeepSeek-V3",
          "type": "chat",
          "description": "DeepSeek-V3 is a strong, versatile model for general tasks, coding, and chat.",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "features": [
            "chat",
            "coding",
            "tool-use",
            "json-mode"
          ]
        },
        {
          "id": "deepseek-reasoner",
          "name": "DeepSeek-R1",
          "type": "chat",
          "description": "DeepSeek-R1 is a reasoning model optimized for complex logic, math, and coding tasks.",
          "context_window": 128000,
          "max_output_tokens": 65536,
          "features": [
            "reasoning",
            "math",
            "coding"
          ]
        }
      ]
    },
    {
      "id": "google",
      "name": "Google",
      "description": "Google's multimodal AI models, including Gemini.",
      "website": "https://ai.google.dev",
      "docs_url": "https://ai.google.dev/gemini-api/docs",
      "api_config": {
        "protocol": "rest",
        "protocol_format": "google_gemini",
        "base_url": "https://generativelanguage.googleapis.com/v1beta",
        "auth": {
          "type": "api_key",
          "param_location": "query",
          "param_key": "key",
          "env_var_suggestion": "GOOGLE_API_KEY"
        },
        "endpoints": {
          "generate_content": {
            "path": "/models/{model}:generateContent",
            "method": "POST",
            "supports_stream": true
          },
          "models": {
            "path": "/models",
            "method": "GET"
          }
        },
        "error_codes": [
          {
            "code": "400",
            "description": "Invalid Argument"
          },
          {
            "code": "403",
            "description": "Permission Denied"
          },
          {
            "code": "404",
            "description": "Not Found"
          },
          {
            "code": "429",
            "description": "Resource Exhausted"
          },
          {
            "code": "500",
            "description": "Internal Error"
          },
          {
            "code": "503",
            "description": "Service Unavailable"
          }
        ]
      },
      "pricing_currency": "USD",
      "models": [
        {
          "id": "gemini-3-pro-preview",
          "name": "Gemini 3 Pro Preview",
          "type": "chat",
          "description": "Next-generation model with dynamic thinking and granular media control.",
          "features": [
            "multimodal",
            "thinking",
            "long-context"
          ],
          "context_window": 1000000,
          "max_output_tokens": 64000
        },
        {
          "id": "gemini-2.5-pro",
          "name": "Gemini 2.5 Pro",
          "type": "chat",
          "description": "High-capability model for complex reasoning and coding.",
          "features": [
            "multimodal",
            "reasoning",
            "coding"
          ],
          "context_window": 1000000,
          "max_output_tokens": 8192
        },
        {
          "id": "gemini-2.5-flash",
          "name": "Gemini 2.5 Flash",
          "type": "chat",
          "description": "Designed for real-time, bidirectional streaming with Gemini Live API.",
          "features": [
            "multimodal",
            "fast",
            "real-time"
          ],
          "context_window": 1000000,
          "max_output_tokens": 8192
        }
      ]
    },
    {
      "id": "openai",
      "name": "OpenAI",
      "description": "The AI research and deployment company behind GPT models.",
      "website": "https://openai.com",
      "docs_url": "https://platform.openai.com/docs/api-reference",
      "api_config": {
        "protocol": "rest",
        "protocol_format": "openai",
        "base_url": "https://api.openai.com/v1",
        "auth": {
          "type": "api_key",
          "header_key": "Authorization",
          "token_prefix": "Bearer",
          "env_var_suggestion": "OPENAI_API_KEY"
        },
        "endpoints": {
          "chat": {
            "path": "/chat/completions",
            "method": "POST",
            "supports_stream": true
          },
          "embeddings": {
            "path": "/embeddings",
            "method": "POST"
          },
          "models": {
            "path": "/models",
            "method": "GET"
          }
        },
        "error_codes": [
          {
            "code": "400",
            "description": "Bad Request"
          },
          {
            "code": "401",
            "description": "Unauthorized"
          },
          {
            "code": "403",
            "description": "Forbidden"
          },
          {
            "code": "429",
            "description": "Rate Limit Exceeded"
          },
          {
            "code": "500",
            "description": "Internal Server Error"
          },
          {
            "code": "503",
            "description": "Service Unavailable"
          }
        ]
      },
      "pricing_currency": "USD",
      "models": [
        {
          "id": "gpt-5.2",
          "name": "GPT-5.2",
          "type": "chat",
          "description": "The best model for coding and agentic tasks across industries.",
          "features": [
            "coding",
            "agentic"
          ],
          "context_window": 200000,
          "max_output_tokens": 16384
        },
        {
          "id": "gpt-5.2-pro",
          "name": "GPT-5.2 Pro",
          "type": "chat",
          "description": "Version of GPT-5.2 that produces smarter and more precise responses.",
          "features": [
            "coding",
            "agentic",
            "precise"
          ],
          "context_window": 200000,
          "max_output_tokens": 16384
        },
        {
          "id": "gpt-5",
          "name": "GPT-5",
          "type": "chat",
          "description": "Previous intelligent reasoning model for coding and agentic tasks with configurable reasoning effort.",
          "features": [
            "reasoning",
            "coding",
            "agentic"
          ],
          "context_window": 128000,
          "max_output_tokens": 16384
        },
        {
          "id": "gpt-5-mini",
          "name": "GPT-5 Mini",
          "type": "chat",
          "description": "A faster, cost-efficient version of GPT-5 for well-defined tasks.",
          "features": [
            "fast",
            "cost-efficient"
          ],
          "context_window": 128000,
          "max_output_tokens": 16384
        },
        {
          "id": "gpt-5-nano",
          "name": "GPT-5 Nano",
          "type": "chat",
          "description": "Fastest, most cost-efficient version of GPT-5.",
          "features": [
            "fastest",
            "cost-efficient"
          ],
          "context_window": 32768,
          "max_output_tokens": 4096
        },
        {
          "id": "gpt-4.1",
          "name": "GPT-4.1",
          "type": "chat",
          "description": "Smartest non-reasoning model.",
          "features": [
            "non-reasoning"
          ],
          "context_window": 128000,
          "max_output_tokens": 16384
        },
        {
          "id": "sora-2",
          "name": "Sora 2",
          "type": "video",
          "description": "Flagship video generation with synced audio.",
          "features": [
            "video",
            "audio"
          ]
        },
        {
          "id": "sora-2-pro",
          "name": "Sora 2 Pro",
          "type": "video",
          "description": "Most advanced synced-audio video generation.",
          "features": [
            "video",
            "audio",
            "advanced"
          ]
        },
        {
          "id": "gpt-image-1.5",
          "name": "GPT Image 1.5",
          "type": "image",
          "description": "State-of-the-art image generation model.",
          "features": [
            "image-generation"
          ]
        },
        {
          "id": "gpt-realtime",
          "name": "GPT Realtime",
          "type": "chat",
          "description": "Model capable of realtime text and audio inputs and outputs.",
          "features": [
            "realtime",
            "audio",
            "text"
          ],
          "context_window": 128000,
          "max_output_tokens": 4096
        }
      ]
    },
    {
      "id": "zhipuai",
      "name": "Zhipu AI",
      "description": "Zhipu AI (智谱AI) provides the GLM series of models, known for complex reasoning and long context capabilities.",
      "website": "https://open.bigmodel.cn/",
      "docs_url": "https://open.bigmodel.cn/dev/api/normal-model/glm-4",
      "api_config": {
        "protocol": "rest",
        "protocol_format": "openai",
        "base_url": "https://open.bigmodel.cn/api/paas/v4",
        "auth": {
          "type": "api_key",
          "header_key": "Authorization",
          "token_prefix": "Bearer",
          "env_var_suggestion": "ZHIPUAI_API_KEY",
          "instructions": "Use the API Key (format: {id}.{secret}) directly as the Bearer token. Alternatively, you can generate a JWT token using the key."
        },
        "endpoints": {
          "chat": {
            "path": "/chat/completions",
            "docs_url": "https://open.bigmodel.cn/dev/api/normal-model/glm-4#chat-completions",
            "description": "Synchronous call, wait for the model to complete execution and return the final result or use SSE call.",
            "method": "POST",
            "request_content_type": "application/json",
            "response_content_type": [
              "application/json",
              "text/event-stream"
            ],
            "character_encoding": "UTF-8",
            "supports_stream": true,
            "request_parameters": {
              "model": {
                "type": "string",
                "format": "string",
                "required": true,
                "description": "The ID of the model to use (e.g., 'glm-4-plus')."
              },
              "messages": {
                "type": "array",
                "format": "array",
                "required": true,
                "description": "A list of messages comprising the conversation so far.",
                "items": {
                  "type": "object",
                  "format": "object",
                  "properties": {
                    "role": {
                      "type": "string",
                      "format": "string",
                      "enum": [
                        "system",
                        "user",
                        "assistant",
                        "tool"
                      ],
                      "description": "The role of the messages author."
                    },
                    "content": {
                      "type": "string",
                      "format": "string",
                      "description": "The contents of the message."
                    },
                    "tool_calls": {
                      "type": "array",
                      "format": "array",
                      "description": "The tool calls generated by the model, such as function calls."
                    }
                  },
                  "required": [
                    "role",
                    "content"
                  ]
                }
              },
              "request_id": {
                "type": "string",
                "format": "string",
                "required": false,
                "description": "Unique identifier for the request, generated by the client."
              },
              "do_sample": {
                "type": "boolean",
                "format": "boolean",
                "required": false,
                "default": true,
                "description": "Whether to use sampling; use false for deterministic results."
              },
              "stream": {
                "type": "boolean",
                "format": "boolean",
                "required": false,
                "default": false,
                "description": "If true, partial message deltas will be sent as data-only server-sent events."
              },
              "temperature": {
                "type": "number",
                "format": "float",
                "required": false,
                "default": 0.95,
                "minimum": 0.0,
                "maximum": 1.0,
                "description": "Sampling temperature. Higher values mean more random outputs."
              },
              "top_p": {
                "type": "number",
                "format": "float",
                "required": false,
                "default": 0.7,
                "minimum": 0.0,
                "maximum": 1.0,
                "description": "Nucleus sampling. Model considers the results of the tokens with top_p probability mass."
              },
              "max_tokens": {
                "type": "integer",
                "format": "int32",
                "required": false,
                "description": "The maximum number of tokens to generate in the completion."
              },
              "stop": {
                "type": "array",
                "format": "array",
                "required": false,
                "items": {
                  "type": "string",
                  "format": "string"
                },
                "description": "Up to 4 sequences where the API will stop generating further tokens."
              },
              "tools": {
                "type": "array",
                "format": "array",
                "required": false,
                "description": "A list of tools the model may call. Currently, only functions are supported as a tool.",
                "items": {
                  "type": "object",
                  "format": "object",
                  "properties": {
                    "type": {
                      "type": "string",
                      "format": "string",
                      "enum": [
                        "function",
                        "retrieval",
                        "web_search"
                      ],
                      "description": "The type of the tool."
                    },
                    "function": {
                      "type": "object",
                      "format": "object",
                      "description": "Function definition."
                    },
                    "retrieval": {
                      "type": "object",
                      "format": "object",
                      "description": "Retrieval tool configuration."
                    },
                    "web_search": {
                      "type": "object",
                      "format": "object",
                      "description": "Web search tool configuration."
                    }
                  }
                }
              },
              "tool_choice": {
                "type": "string",
                "format": "string",
                "required": false,
                "default": "auto",
                "enum": [
                  "auto",
                  "none"
                ],
                "description": "Controls which (if any) tool is called by the model."
              },
              "user_id": {
                "type": "string",
                "format": "string",
                "required": false,
                "description": "A unique identifier representing your end-user."
              }
            },
            "response_parameters": {
              "id": {
                "type": "string",
                "format": "string",
                "description": "A unique identifier for the chat completion."
              },
              "created": {
                "type": "integer",
                "format": "int64",
                "description": "The Unix timestamp (in seconds) of when the chat completion was created."
              },
              "model": {
                "type": "string",
                "format": "string",
                "description": "The model used for the chat completion."
              },
              "choices": {
                "type": "array",
                "format": "array",
                "description": "A list of chat completion choices.",
                "items": {
                  "type": "object",
                  "format": "object",
                  "properties": {
                    "index": {
                      "type": "integer",
                      "format": "int32",
                      "description": "The index of the choice in the list of choices."
                    },
                    "message": {
                      "type": "object",
                      "format": "object",
                      "description": "The chat completion message generated by the model.",
                      "properties": {
                        "role": {
                          "type": "string",
                          "format": "string",
                          "description": "The role of the author of this message."
                        },
                        "content": {
                          "type": "string",
                          "format": "string",
                          "description": "The contents of the message."
                        },
                        "tool_calls": {
                          "type": "array",
                          "format": "array",
                          "description": "The tool calls generated by the model, such as function calls."
                        }
                      }
                    },
                    "finish_reason": {
                      "type": "string",
                      "format": "string",
                      "description": "The reason the model stopped generating tokens."
                    }
                  }
                }
              },
              "usage": {
                "type": "object",
                "format": "object",
                "description": "Usage statistics for the completion request.",
                "properties": {
                  "prompt_tokens": {
                    "type": "integer",
                    "format": "int32",
                    "description": "Number of tokens in the prompt."
                  },
                  "completion_tokens": {
                    "type": "integer",
                    "format": "int32",
                    "description": "Number of tokens in the generated completion."
                  },
                  "total_tokens": {
                    "type": "integer",
                    "format": "int32",
                    "description": "Total number of tokens used in the request (prompt + completion)."
                  }
                }
              }
            }
          },
          "embeddings": {
            "path": "/embeddings",
            "method": "POST"
          }
        },
        "error_codes": [
          {
            "code": "200",
            "description": "Success"
          },
          {
            "code": "400",
            "description": "Invalid parameter or request format"
          },
          {
            "code": "401",
            "description": "Authentication failed or token expired"
          },
          {
            "code": "404",
            "description": "Resource not found (model, fine-tuning task)"
          },
          {
            "code": "429",
            "description": "Rate limit exceeded or insufficient quota"
          },
          {
            "code": "434",
            "description": "No API permission"
          },
          {
            "code": "435",
            "description": "File size exceeds limit"
          },
          {
            "code": "500",
            "description": "Internal server error"
          },
          {
            "code": "1000",
            "description": "Authentication failed"
          },
          {
            "code": "1001",
            "description": "Missing Authentication header"
          },
          {
            "code": "1002",
            "description": "Invalid Authentication Token"
          },
          {
            "code": "1003",
            "description": "Authentication Token expired"
          },
          {
            "code": "1004",
            "description": "Authentication Token verification failed"
          },
          {
            "code": "1100",
            "description": "Account read/write error"
          },
          {
            "code": "1110",
            "description": "Account inactive"
          },
          {
            "code": "1111",
            "description": "Account does not exist"
          },
          {
            "code": "1112",
            "description": "Account locked"
          },
          {
            "code": "1113",
            "description": "Account arrears"
          },
          {
            "code": "1120",
            "description": "Account access failed"
          },
          {
            "code": "1121",
            "description": "Account locked due to violation"
          },
          {
            "code": "1200",
            "description": "API call error"
          },
          {
            "code": "1210",
            "description": "Invalid API parameters"
          },
          {
            "code": "1211",
            "description": "Model does not exist"
          },
          {
            "code": "1212",
            "description": "Method not supported by current model"
          },
          {
            "code": "1213",
            "description": "Missing required parameter"
          },
          {
            "code": "1214",
            "description": "Invalid parameter value"
          },
          {
            "code": "1215",
            "description": "Conflicting parameters"
          },
          {
            "code": "1220",
            "description": "No permission to access API"
          },
          {
            "code": "1221",
            "description": "API deprecated"
          },
          {
            "code": "1222",
            "description": "API does not exist"
          },
          {
            "code": "1230",
            "description": "API workflow error"
          },
          {
            "code": "1231",
            "description": "Duplicate request ID"
          },
          {
            "code": "1234",
            "description": "Network error"
          },
          {
            "code": "1300",
            "description": "Blocked by policy"
          },
          {
            "code": "1301",
            "description": "Sensitive content detected"
          },
          {
            "code": "1302",
            "description": "High concurrency limit exceeded"
          },
          {
            "code": "1303",
            "description": "High frequency limit exceeded"
          },
          {
            "code": "1304",
            "description": "Daily usage limit reached"
          },
          {
            "code": "1305",
            "description": "Traffic limit triggered"
          },
          {
            "code": "1308",
            "description": "Usage cap reached"
          },
          {
            "code": "1309",
            "description": "Plan expired"
          }
        ]
      },
      "pricing_currency": "CNY",
      "models": [
        {
          "id": "glm-4.5",
          "name": "GLM-4.5",
          "type": "chat",
          "description": "Latest flagship model (2025) with enhanced capabilities.",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "features": [
            "tool_calling",
            "web_search",
            "function_calling"
          ]
        },
        {
          "id": "glm-4.5-air",
          "name": "GLM-4.5 Air",
          "type": "chat",
          "description": "Cost-effective version of GLM-4.5.",
          "context_window": 128000,
          "max_output_tokens": 16384,
          "features": [
            "tool_calling",
            "web_search",
            "function_calling"
          ]
        },
        {
          "id": "glm-4.6",
          "name": "GLM-4.6",
          "type": "chat",
          "description": "Next-generation model (2025).",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "features": [
            "tool_calling",
            "web_search",
            "function_calling"
          ]
        },
        {
          "id": "glm-4.7",
          "name": "GLM-4.7",
          "type": "chat",
          "description": "Advanced reasoning model (2026).",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "features": [
            "tool_calling",
            "web_search",
            "function_calling"
          ]
        }
      ]
    }
  ]
}