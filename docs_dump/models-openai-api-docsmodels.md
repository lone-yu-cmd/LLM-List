---
title: Models | OpenAI API
url: https://platform.openai.com/docs/models
---

Search`⌘``K`

Get started

[Overview](/docs/overview)

[Quickstart](/docs/quickstart)

[Models](/docs/models)

[Pricing](/docs/pricing)

[Libraries](/docs/libraries)

[Latest: GPT-5.2](/docs/guides/latest-model)

Core concepts

[Text generation](/docs/guides/text)

[Code generation](/docs/guides/code-generation)

[Images and vision](/docs/guides/images-vision)

[Audio and speech](/docs/guides/audio)

[Structured output](/docs/guides/structured-outputs)

[Function calling](/docs/guides/function-calling)

[Responses API](/docs/guides/migrate-to-responses)

Agents

[Overview](/docs/guides/agents)

Build agents

Deploy in your product

Optimize

[Voice agents](/docs/guides/voice-agents)

Tools

[Using tools](/docs/guides/tools)

[Connectors and MCP](/docs/guides/tools-connectors-mcp)

[Web search](/docs/guides/tools-web-search)

[Code interpreter](/docs/guides/tools-code-interpreter)

File search and retrieval

More tools

Run and scale

[Conversation state](/docs/guides/conversation-state)

[Background mode](/docs/guides/background)

[Streaming](/docs/guides/streaming-responses)

[Webhooks](/docs/guides/webhooks)

[File inputs](/docs/guides/pdf-files)

Prompting

Reasoning

Evaluation

[Getting started](/docs/guides/evaluation-getting-started)

[Working with evals](/docs/guides/evals)

[Prompt optimizer](/docs/guides/prompt-optimizer)

[External models](/docs/guides/external-models)

[Best practices](/docs/guides/evaluation-best-practices)

Realtime API

[Overview](/docs/guides/realtime)

Connect

Usage

Model optimization

[Optimization cycle](/docs/guides/model-optimization)

Fine-tuning

[Graders](/docs/guides/graders)

Specialized models

[Image generation](/docs/guides/image-generation)

[Video generation](/docs/guides/video-generation)

[Text to speech](/docs/guides/text-to-speech)

[Speech to text](/docs/guides/speech-to-text)

[Deep research](/docs/guides/deep-research)

[Embeddings](/docs/guides/embeddings)

[Moderation](/docs/guides/moderation)

Coding agents

[Codex cloud](https://developers.openai.com/codex/cloud)

[Agent internet access](https://developers.openai.com/codex/cloud/agent-internet)

[Codex CLI](https://developers.openai.com/codex/cli)

[Codex IDE](https://developers.openai.com/codex/ide)

[Codex changelog](https://developers.openai.com/codex/changelog)

Going live

[Production best practices](/docs/guides/production-best-practices)

Latency optimization

Cost optimization

[Accuracy optimization](/docs/guides/optimizing-llm-accuracy)

Safety

Specialized APIs

Assistants API

Resources

[Terms and policies](https://openai.com/policies)

[Changelog](/docs/changelog)

[Your data](/docs/guides/your-data)

[Permissions](/docs/guides/rbac)

[Rate limits](/docs/guides/rate-limits)

[Deprecations](/docs/deprecations)

[MCP for deep research](/docs/mcp)

[Developer mode](/docs/guides/developer-mode)

ChatGPT Actions

[Cookbook](https://cookbook.openai.com)[Forum](https://community.openai.com/categories)

# Models

Explore all available models and compare their capabilities.

Compare models

Featured models

[GPT-5.2NewThe best model for coding and agentic tasks across industries](/docs/models/gpt-5.2)[GPT-5 miniA faster, cost-efficient version of GPT-5 for well-defined tasks](/docs/models/gpt-5-mini)[GPT-5 nanoFastest, most cost-efficient version of GPT-5](/docs/models/gpt-5-nano)

Frontier models

OpenAI's most advanced models, recommended for most tasks.

[![gpt-5.2](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.2.png)GPT-5.2The best model for coding and agentic tasks across industries](/docs/models/gpt-5.2)[![gpt-5-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-mini.png)GPT-5 miniA faster, cost-efficient version of GPT-5 for well-defined tasks](/docs/models/gpt-5-mini)[![gpt-5-nano](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-nano.png)GPT-5 nanoFastest, most cost-efficient version of GPT-5](/docs/models/gpt-5-nano)[![gpt-5.2-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.2-pro.png)GPT-5.2 proVersion of GPT-5.2 that produces smarter and more precise responses.](/docs/models/gpt-5.2-pro)[![gpt-5](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.png)GPT-5Previous intelligent reasoning model for coding and agentic tasks with configurable reasoning effort](/docs/models/gpt-5)[![gpt-4.1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1.png)GPT-4.1Smartest non-reasoning model](/docs/models/gpt-4.1)

Open-weight models

Open-weight models under a permissive Apache 2.0 license.

[![gpt-oss-120b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-120b.png)gpt-oss-120bMost powerful open-weight model, fits into an H100 GPU](/docs/models/gpt-oss-120b)[![gpt-oss-20b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-20b.png)gpt-oss-20bMedium-sized open-weight model for low latency](/docs/models/gpt-oss-20b)

Specialized models

Purpose-built for specific tasks.

[![sora-2](https://cdn.openai.com/API/docs/images/model-page/model-icons/sora-2.png)Sora 2Flagship video generation with synced audio](/docs/models/sora-2)[![sora-2-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/sora-2-pro.png)Sora 2 ProMost advanced synced-audio video generation](/docs/models/sora-2-pro)[![o3-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-deep-research.png)o3-deep-researchOur most powerful deep research model](/docs/models/o3-deep-research)[![o4-mini-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o4-mini-deep-research.png)o4-mini-deep-researchFaster, more affordable deep research model](/docs/models/o4-mini-deep-research)[![gpt-image-1.5](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1.5.png)GPT Image 1.5State-of-the-art image generation model.](/docs/models/gpt-image-1.5)[![chatgpt-image-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/chatgpt-image-latest.png)chatgpt-image-latestImage model used in ChatGPT.](/docs/models/chatgpt-image-latest)[![gpt-image-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1.png)GPT Image 1Our previous image generation model](/docs/models/gpt-image-1)[![gpt-image-1-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1-mini.png)gpt-image-1-miniA cost-efficient version of GPT Image 1](/docs/models/gpt-image-1-mini)[![gpt-4o-mini-tts](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-tts.png)GPT-4o mini TTSText-to-speech model powered by GPT-4o mini](/docs/models/gpt-4o-mini-tts)[![gpt-4o-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-transcribe.png)GPT-4o TranscribeSpeech-to-text model powered by GPT-4o](/docs/models/gpt-4o-transcribe)[![gpt-4o-mini-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-transcribe.png)GPT-4o mini TranscribeSpeech-to-text model powered by GPT-4o mini](/docs/models/gpt-4o-mini-transcribe)

Realtime and audio models

Models for audio use cases and realtime inputs and outputs.

[![gpt-realtime](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-realtime.png)gpt-realtimeModel capable of realtime text and audio inputs and outputs](/docs/models/gpt-realtime)[![gpt-audio](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-audio.png)gpt-audioFor audio inputs and outputs with Chat Completions API](/docs/models/gpt-audio)[![gpt-realtime-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-realtime-mini.png)gpt-realtime-miniA cost-efficient version of GPT Realtime](/docs/models/gpt-realtime-mini)[![gpt-audio-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-audio-mini.png)gpt-audio-miniA cost-efficient version of GPT Audio](/docs/models/gpt-audio-mini)

ChatGPT models

Models used in ChatGPT, not recommended for API use.

[![gpt-5-chat-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-chat-latest.png)GPT-5 ChatGPT-5 model used in ChatGPT](/docs/models/gpt-5-chat-latest)[![chatgpt-4o-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/chatgpt-4o-latest.png)ChatGPT-4oGPT-4o model used in ChatGPT](/docs/models/chatgpt-4o-latest)

All models

Diverse models for a variety of tasks.

[![gpt-5.2](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.2.png)GPT-5.2The best model for coding and agentic tasks across industries](/docs/models/gpt-5.2)[![gpt-5.1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.1.png)GPT-5.1The best model for coding and agentic tasks with configurable reasoning effort](/docs/models/gpt-5.1)[![gpt-5](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.png)GPT-5Previous intelligent reasoning model for coding and agentic tasks with configurable reasoning effort](/docs/models/gpt-5)[![gpt-5-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-mini.png)GPT-5 miniA faster, cost-efficient version of GPT-5 for well-defined tasks](/docs/models/gpt-5-mini)[![gpt-5-nano](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-nano.png)GPT-5 nanoFastest, most cost-efficient version of GPT-5](/docs/models/gpt-5-nano)[![gpt-5.1-codex](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.1-codex.png)GPT-5.1 CodexA version of GPT-5.1 optimized for agentic coding in Codex.](/docs/models/gpt-5.1-codex)[![gpt-5.1-codex-max](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.1-codex-max.png)GPT-5.1-Codex-MaxOur most intelligent coding model optimized for long-horizon, agentic coding tasks.](/docs/models/gpt-5.1-codex-max)[![gpt-5-codex](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-codex.png)GPT-5-CodexA version of GPT-5 optimized for agentic coding in Codex](/docs/models/gpt-5-codex)[![gpt-5.2-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.2-pro.png)GPT-5.2 proVersion of GPT-5.2 that produces smarter and more precise responses.](/docs/models/gpt-5.2-pro)[![gpt-5-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-pro.png)GPT-5 proVersion of GPT-5 that produces smarter and more precise responses](/docs/models/gpt-5-pro)[![sora-2](https://cdn.openai.com/API/docs/images/model-page/model-icons/sora-2.png)Sora 2Flagship video generation with synced audio](/docs/models/sora-2)[![sora-2-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/sora-2-pro.png)Sora 2 ProMost advanced synced-audio video generation](/docs/models/sora-2-pro)[![gpt-image-1.5](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1.5.png)GPT Image 1.5State-of-the-art image generation model.](/docs/models/gpt-image-1.5)[![chatgpt-image-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/chatgpt-image-latest.png)chatgpt-image-latestImage model used in ChatGPT.](/docs/models/chatgpt-image-latest)[![gpt-image-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1.png)GPT Image 1Our previous image generation model](/docs/models/gpt-image-1)[![gpt-image-1-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-image-1-mini.png)gpt-image-1-miniA cost-efficient version of GPT Image 1](/docs/models/gpt-image-1-mini)[![o3-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-deep-research.png)o3-deep-researchOur most powerful deep research model](/docs/models/o3-deep-research)[![o4-mini-deep-research](https://cdn.openai.com/API/docs/images/model-page/model-icons/o4-mini-deep-research.png)o4-mini-deep-researchFaster, more affordable deep research model](/docs/models/o4-mini-deep-research)[![o3-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-pro.png)o3-proVersion of o3 with more compute for better responses](/docs/models/o3-pro)[![gpt-audio](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-audio.png)gpt-audioFor audio inputs and outputs with Chat Completions API](/docs/models/gpt-audio)[![gpt-realtime](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-realtime.png)gpt-realtimeModel capable of realtime text and audio inputs and outputs](/docs/models/gpt-realtime)[![gpt-realtime-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-realtime-mini.png)gpt-realtime-miniA cost-efficient version of GPT Realtime](/docs/models/gpt-realtime-mini)[![gpt-audio-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-audio-mini.png)gpt-audio-miniA cost-efficient version of GPT Audio](/docs/models/gpt-audio-mini)[![o3](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3.png)o3Reasoning model for complex tasks, succeeded by GPT-5](/docs/models/o3)[![o4-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o4-mini.png)o4-miniFast, cost-efficient reasoning model, succeeded by GPT-5 mini](/docs/models/o4-mini)[![gpt-4.1](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1.png)GPT-4.1Smartest non-reasoning model](/docs/models/gpt-4.1)[![gpt-4.1-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1-mini.png)GPT-4.1 miniSmaller, faster version of GPT-4.1](/docs/models/gpt-4.1-mini)[![gpt-4.1-nano](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.1-nano.png)GPT-4.1 nanoFastest, most cost-efficient version of GPT-4.1](/docs/models/gpt-4.1-nano)[![o1-pro](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-pro.png)o1-proVersion of o1 with more compute for better responses](/docs/models/o1-pro)[![computer-use-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/computer-use-preview.png)computer-use-previewSpecialized model for computer use tool](/docs/models/computer-use-preview)[![gpt-4o-mini-search-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-search-preview.png)GPT-4o mini Search PreviewFast, affordable small model for web search](/docs/models/gpt-4o-mini-search-preview)[![gpt-4o-search-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-search-preview.png)GPT-4o Search PreviewGPT model for web search in Chat Completions](/docs/models/gpt-4o-search-preview)[![gpt-4.5-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.5-preview.png)GPT-4.5 Preview (Deprecated)Deprecated large model.](/docs/models/gpt-4.5-preview)[![o3-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o3-mini.png)o3-miniA small model alternative to o3](/docs/models/o3-mini)[![o1](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1.png)o1Previous full o-series reasoning model](/docs/models/o1)[![omni-moderation-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/omni-moderation-latest.png)omni-moderationIdentify potentially harmful content in text and images](/docs/models/omni-moderation-latest)[![o1-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-mini.png)o1-miniDeprecatedA small model alternative to o1](/docs/models/o1-mini)[![o1-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/o1-preview.png)o1 PreviewDeprecatedPreview of our first o-series reasoning model](/docs/models/o1-preview)[![gpt-4o](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o.png)GPT-4oFast, intelligent, flexible GPT model](/docs/models/gpt-4o)[![gpt-4o-audio-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-audio-preview.png)GPT-4o AudioGPT-4o models capable of audio inputs and outputs](/docs/models/gpt-4o-audio-preview)[![gpt-4o-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini.png)GPT-4o miniFast, affordable small model for focused tasks](/docs/models/gpt-4o-mini)[![gpt-4o-mini-audio-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-audio-preview.png)GPT-4o mini AudioSmaller model capable of audio inputs and outputs](/docs/models/gpt-4o-mini-audio-preview)[![gpt-4o-mini-realtime-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-realtime-preview.png)GPT-4o mini RealtimeSmaller realtime model for text and audio inputs and outputs](/docs/models/gpt-4o-mini-realtime-preview)[![gpt-4o-realtime-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-realtime-preview.png)GPT-4o RealtimeModel capable of realtime text and audio inputs and outputs](/docs/models/gpt-4o-realtime-preview)[![gpt-4-turbo](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4-turbo.png)GPT-4 TurboAn older high-intelligence GPT model](/docs/models/gpt-4-turbo)[![babbage-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/babbage-002.png)babbage-002DeprecatedReplacement for the GPT-3 ada and babbage base models](/docs/models/babbage-002)[![chatgpt-4o-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/chatgpt-4o-latest.png)ChatGPT-4oGPT-4o model used in ChatGPT](/docs/models/chatgpt-4o-latest)[![gpt-5.1-codex-mini](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.1-codex-mini.png)GPT-5.1 Codex miniSmaller, more cost-effective, less-capable version of GPT-5.1-Codex](/docs/models/gpt-5.1-codex-mini)[![codex-mini-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/codex-mini-latest.png)codex-mini-latestDeprecatedFast reasoning model optimized for the Codex CLI](/docs/models/codex-mini-latest)[![dall-e-2](https://cdn.openai.com/API/docs/images/model-page/model-icons/dall-e-2.png)DALL·E 2DeprecatedOur first image generation model](/docs/models/dall-e-2)[![dall-e-3](https://cdn.openai.com/API/docs/images/model-page/model-icons/dall-e-3.png)DALL·E 3DeprecatedPrevious generation image generation model](/docs/models/dall-e-3)[![davinci-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/davinci-002.png)davinci-002DeprecatedReplacement for the GPT-3 curie and davinci base models](/docs/models/davinci-002)[![gpt-3.5-turbo](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-3.5-turbo.png)GPT-3.5 TurboLegacy GPT model for cheaper chat and non-chat tasks](/docs/models/gpt-3.5-turbo)[![gpt-4](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4.png)GPT-4An older high-intelligence GPT model](/docs/models/gpt-4)[![gpt-4-turbo-preview](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4-turbo-preview.png)GPT-4 Turbo PreviewDeprecatedAn older fast GPT model](/docs/models/gpt-4-turbo-preview)[![gpt-4o-mini-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-transcribe.png)GPT-4o mini TranscribeSpeech-to-text model powered by GPT-4o mini](/docs/models/gpt-4o-mini-transcribe)[![gpt-4o-mini-tts](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-mini-tts.png)GPT-4o mini TTSText-to-speech model powered by GPT-4o mini](/docs/models/gpt-4o-mini-tts)[![gpt-4o-transcribe](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-transcribe.png)GPT-4o TranscribeSpeech-to-text model powered by GPT-4o](/docs/models/gpt-4o-transcribe)[![gpt-4o-transcribe-diarize](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-4o-transcribe-diarize.png)GPT-4o Transcribe DiarizeTranscription model that identifies who's speaking when](/docs/models/gpt-4o-transcribe-diarize)[![gpt-5.2-chat-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.2-chat-latest.png)GPT-5.2 ChatGPT-5.2 model used in ChatGPT](/docs/models/gpt-5.2-chat-latest)[![gpt-5.1-chat-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5.1-chat-latest.png)GPT-5.1 ChatGPT-5.1 model used in ChatGPT](/docs/models/gpt-5.1-chat-latest)[![gpt-5-chat-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-5-chat-latest.png)GPT-5 ChatGPT-5 model used in ChatGPT](/docs/models/gpt-5-chat-latest)[![gpt-oss-120b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-120b.png)gpt-oss-120bMost powerful open-weight model, fits into an H100 GPU](/docs/models/gpt-oss-120b)[![gpt-oss-20b](https://cdn.openai.com/API/docs/images/model-page/model-icons/gpt-oss-20b.png)gpt-oss-20bMedium-sized open-weight model for low latency](/docs/models/gpt-oss-20b)[![text-embedding-3-large](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-3-large.png)text-embedding-3-largeMost capable embedding model](/docs/models/text-embedding-3-large)[![text-embedding-3-small](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-3-small.png)text-embedding-3-smallSmall embedding model](/docs/models/text-embedding-3-small)[![text-embedding-ada-002](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-embedding-ada-002.png)text-embedding-ada-002Older embedding model](/docs/models/text-embedding-ada-002)[![text-moderation-latest](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-moderation-latest.png)text-moderationDeprecatedPrevious generation text-only moderation model](/docs/models/text-moderation-latest)[![text-moderation-stable](https://cdn.openai.com/API/docs/images/model-page/model-icons/text-moderation-stable.png)text-moderation-stableDeprecatedPrevious generation text-only moderation model](/docs/models/text-moderation-stable)[![tts-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/tts-1.png)TTS-1Text-to-speech model optimized for speed](/docs/models/tts-1)[![tts-1-hd](https://cdn.openai.com/API/docs/images/model-page/model-icons/tts-1-hd.png)TTS-1 HDText-to-speech model optimized for quality](/docs/models/tts-1-hd)[![whisper-1](https://cdn.openai.com/API/docs/images/model-page/model-icons/whisper-1.png)WhisperGeneral-purpose speech recognition model](/docs/models/whisper-1)

[How we use your data](/docs/guides/your-data)·[Deprecated models](/docs/deprecations)
